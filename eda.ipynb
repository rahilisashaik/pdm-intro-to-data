{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"https://static.wixstatic.com/media/9278e7_c8e6664df6e44185b1da6e60e9e8da6c~mv2.png/v1/fill/w_110,h_110,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/black_logo.png\">\n",
    "\n",
    "# Sp25 PDM Intro to Data\n",
    "Built and presented by Shivani Sahni and Rahil Shaik\n",
    "\n",
    "March 19th 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Introduction to Jupyter Notebooks\n",
    "\n",
    "#### 1.1: Introduction to Jupyter Notebooks:\n",
    "Jupyter Notebooks are interactive documents that combine code, text, and visualizations, making them ideal for data analysis and teaching.â€‹ These are commonplace in research, machine learning, and quantitative finance settings to perform exploratory data work. It enables us to run different experiments to see how we can improve a model's performance in a streamlined and convenient manner.\n",
    "\n",
    "#### 1.2: Operating a Jupyter Notebook:\n",
    "\n",
    "- Running Cells: Each notebook consists of cells that can contain code or text. To execute a code cell, click on it and press `Shift + Enter`. There is also a button when you hover a cell that resembles a play button that allows you to run the cell. \n",
    "\n",
    "- Creating Cells: You can make two types of cells in python notebooks: markdown and code. Markdowns are generally used to add explanatory text around your code cells. Code cells are used for... coding! There are options at the top taskbar to choose between markdown and code. If you double clik into this cell you can see the scripting for this markdown! \n",
    "\n",
    "#### 1.3: Understanding how Kernel's work\n",
    "A kernel is the computational engine that executes the code in the notebook. We will select a python kernel to execute the cells in this python notebook. If the kernel stops or \"dies\", you can restart it with the above taskbar using 'Kernel' > 'Restart'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Python and Pandas Basics\n",
    "\n",
    "#### 2.1: Setting up your Python environment\n",
    "There are a few options here including installing Python to your local system, creating a Python virtual environment (venv, conda). Today we will create a python venv virtual environment because they are genearlly lightweight and a major advantage being that you can create isolated environments that use different versions of libraries or Python itself.\n",
    "\n",
    "If you are using macOS, you need to install Homebrew, which helps manage packages easily (I think you guys all have macOS). Access your terminal and run the below commands:\n",
    "\n",
    "`/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"`\n",
    "\n",
    "`echo 'eval \"$(/opt/homebrew/bin/brew shellenv)\"' >> ~/.zprofile`\n",
    "\n",
    "`eval \"$(/opt/homebrew/bin/brew shellenv)\" `\n",
    "\n",
    "To ensure you have installed brew, run this command\n",
    "\n",
    "`brew --version`\n",
    "\n",
    "Then install python and git\n",
    "\n",
    "`brew install python`\n",
    "\n",
    "`brew install git`\n",
    "\n",
    "Then you can clone the PDM repository using the git script\n",
    "\n",
    "`git clone https://github.com/rahilisashaik/pdm-intro-to-data.git`\n",
    "\n",
    "You should then access this directory in visual studio code, google colab, or where ever you would like. I assume it is at your default directory:\n",
    "\n",
    "`/Users/rahilshaik/pdm-intro-to-data` or `~/pdm-intro-to-data`\n",
    "\n",
    "For the rest of these instructions, you should be in the built in terminal for your coding environment (colab, vs code, jupyter)\n",
    "\n",
    "Check if python installed correctly with\n",
    "\n",
    "`python3 --version`\n",
    "\n",
    "`pip --version` or `pip3 --version`\n",
    "\n",
    "Now we can create a python virtual environment for this project using the below commands\n",
    "\n",
    "`python -m venv pdmdata` or `python3 -m venv pdmdata`\n",
    "\n",
    "`source pdmdata/bin/activate`\n",
    "\n",
    "Pip is a package manger, if any point you get `ModuleNotFoundError`, you can use pip to install those packages. I have listed the package requirements for this project in the 'requirements.txt' file, we can use pip to install them. \n",
    "\n",
    "`pip3 install -r requirements.txt`\n",
    "\n",
    "\n",
    "Now you're ready to start coding!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2: Basics of Python\n",
    "\n",
    "First we'll talk about variables, variable types, and how python interprets and stores data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are a bunch of package imports, the great thing about coding in 2025 is the grunt work is \n",
    "# almost always done for you so you can just import packages that do tasks for you\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Integer\n",
    "x = 10  \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.5\n"
     ]
    }
   ],
   "source": [
    "# Float\n",
    "y = 10.5  \n",
    "print(y)  # <class 'float'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leponda\n"
     ]
    }
   ],
   "source": [
    "# String\n",
    "name = \"Leponda\"\n",
    "print(name)  # <class 'str'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Boolean\n",
    "is_student = True\n",
    "print(is_student)  # <class 'bool'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gurnoor', 'arjun', 'sarah', 'katie', 'sadie', 'aathma', 'jay']\n",
      "[4, 4, -1, 8, 16, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "pledges = [\"gurnoor\", \"arjun\", \"sarah\", \"katie\", \"sadie\", \"aathma\", \"jay\"]\n",
    "pledge_points = [4, 4, -1, 8, 16, 4, 4] # as of 03/17 at 7:21 PM\n",
    "\n",
    "print(pledges)  # <class 'list'>\n",
    "print(pledge_points)  # <class 'list'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few manipulations you can do with lists that are pretty useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guess what this will do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1, 2, 3] + [4, 5, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're using numpy arrays, similar to lists but guess what this will return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, 2, 3]) + np.array([4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  6,  9],\n",
       "       [12, 15, 18],\n",
       "       [21, 24, 27]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3],\n",
    "             [4, 5, 6],\n",
    "             [7, 8, 9]])\n",
    "\n",
    "b = np.array([[2, 4, 6,],\n",
    "             [8, 10, 12],\n",
    "             [14, 16, 18]])\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try this out yourself! Create a 3 x 3 matrix like such:\n",
    "\n",
    "$$ \\begin{bmatrix}\n",
    "1 & 2 & 3\\\\\n",
    "4 & 5 & 6\\\\\n",
    "7 & 6 & 9\\\\\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "Then, output a matrix where each column is subtracted by its (each column's) average.  \n",
    "_Hint: use np.mean(axis=0)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: define np.array with the above items\n",
    "arr = np.array([[1,2, 3],\n",
    "                [4,5, 6],\n",
    "                [7, 8,9]\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: get means of each column and subtract from each column in matrix\n",
    "means = np.mean(arr, axis=0)\n",
    "output = arr - means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3., -3., -3.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 3.,  3.,  3.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: print the output\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary (key-value pairs)\n",
    "trash_pledge_leaderboard = {\"top_pledge\": \"rahil\", \"bottom_pledge\": \"shivani\"}\n",
    "print(trash_pledge_leaderboard)  # <class 'dict'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't look right, let's use the lists we created and update the dictionary with the correct pledge and pledge points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pledge_to_points = zip(pledges, pledge_points)\n",
    "pledge_leaderboard = dict(pledge_to_points)\n",
    "\n",
    "print(pledge_leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use some python syntax to return the top and bottom pledge. We'll start with a brief overview of for loops and if statements in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pledge in pledges:\n",
    "    print(pledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pledges)):\n",
    "    print(pledges[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pledge, points in pledge_leaderboard.items():\n",
    "    if points > np.mean(pledge_points):\n",
    "        print(\"The pledges doing above average are\", pledge)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_points = float('inf')\n",
    "most_points = float('-inf')\n",
    "\n",
    "bottom_pledge = \"\"\n",
    "top_pledge = \"\"\n",
    "\n",
    "for pledge, points in pledge_leaderboard.items():\n",
    "    if points < least_points:\n",
    "        least_points = points\n",
    "        bottom_pledge = pledge\n",
    "        \n",
    "    if points > most_points:\n",
    "        most_points = points\n",
    "        top_pledge = pledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"top pledge is\", top_pledge, \"with\", pledge_leaderboard[top_pledge], \"points\")\n",
    "print(\"bottom pledge is\", bottom_pledge, \"with\", pledge_leaderboard[bottom_pledge], \"points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last piece of syntax we'll go over is indexing and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pledges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct indexing\n",
    "pledges[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pledges[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use slicing:\n",
    "\n",
    "`list[start:end:step]`\n",
    "\n",
    "If you leave `start` blank it will default to 0\n",
    "If you leave `end` blank it will default to the last item in the list\n",
    "If you leave `step` blank it will default to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pledges[1:6:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3: Using Pandas for Exploratory Data Analysis\n",
    "We will use a data set from sklearn to practice about california housing, pandas enables us to read this information in as a 'dataframe'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `.head()` to get the first 5 rows of your data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few operations on the dataframe you can use to extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()  # Show first 5 rows\n",
    "# df.tail(3)  # Show last 3 rows\n",
    "# df.shape  # Get number of rows and columns\n",
    "# df.columns  # List column names\n",
    "# df[\"MedInc\"].value_counts() # summary of specific value occurences for a set\n",
    "df.describe()  # Summary statistics for numerical columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can reference specific column names using brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"MedInc\"]  # Select a single column (returns a Series)\n",
    "df[[\"MedInc\", \"HouseAge\"]]  # Select multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two methods to access specific partitions of the dataframe in pandas including `.query()` and bracket notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"MedInc > 5.6431 and HouseAge > 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"MedInc\"] > 5) & (df[\"HouseAge\"] > 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"MedInc\"] > 5) | (df[\"HouseAge\"] > 20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get specfic rows and columns using `.iloc[]` and `.loc[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]  # Select first row (by index)\n",
    "df.iloc[:3]  # Select first three rows\n",
    "\n",
    "df.loc[0, \"MedInc\"]  # Select a specific value (row 0, column \"Name\")\n",
    "df.loc[:, \"HouseAge\"]  # Select all rows for \"Age\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next pandas operations we will cover is sorting which you can do in ascending and descending order and also across multiple columns\n",
    "\n",
    "args:\n",
    "\n",
    "`by` decides which columns to sort by\n",
    "\n",
    "`ascending` dictates the order of sorting (increasing, decreasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"HouseAge\")  # Sort by HouseAge (ascending)\n",
    "df.sort_values(by=\"HouseAge\", ascending=False)  # Sort by HouseAge (descending)\n",
    "df.sort_values(by=[\"HouseAge\", \"MedInc\"], ascending=[True, False])  # Sort by multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have an understanding of how to view different parts of the dataframe, you can create your own columns using the below commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"MedIncNorm\"] = (df[\"MedInc\"] - min(df[\"MedInc\"])) / (max(df[\"MedInc\"]) - min(df[\"MedInc\"]))  # Adding new column normalizing between 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you realize adding that column is a dumb ass idea, you can `.drop()` the column\n",
    "\n",
    "`axis` indicates whether to do the operation across all column or all rows (axis = 1 performs operations across rows and axis = 0 performs operations across columns)\n",
    "\n",
    "`inplace` dictates whether you mutate the original dataframe or create a copy dataframe with the operation updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Drop MedIncNorm column from dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll explore aggregation & grouping across columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"MedInc\"].mean()  # Average salary\n",
    "df[\"MedInc\"].min()  # Minimum age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also aggregate HouseAges together and take their mean. For example, for a HouseAge of 1.0, we get a 'Population' mean of 328.500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"HouseAge\")[\"Population\"].mean().head(5)  # Average salary per age group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readability of your code and dataframe are very important, some of these column names are not super readable so let's `.rename()` them\n",
    "\n",
    "`columns` key-value pairs that map old column name to new column name\n",
    "\n",
    "`inplace` same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"MedInc\": \"MedianIncome\"}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also improve readability of code using comment lines to document commands. Highlight any block of code and hit `Cmd + /` to comment all of it. Without highlighting anything, `Cmd + /` will comment the current line you're on. Generally adding a `#` before any line will make it commented.\n",
    "\n",
    "Use any of the above commenting methods to remove the error from below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below I am printing voyager seniors\n",
    "\n",
    "print(\"shivani\")\n",
    "print(\"christine\")\n",
    "print(\"eric\")\n",
    "print(\"nolan\")\n",
    "print(\"vaarun\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4: Visualization\n",
    "Presenting your findings and visualizing trends is an essential data science skill. We will use matplotlib.pyplot, which is industry standard for data visualization as it provides a lot of freedom in your visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Honestly i think i am better suited doing this for you guys so you can see how plotting works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Basics of Linear Modeling\n",
    "#### 3.1: Building a Linear Model\n",
    "\n",
    "Your objective is to be able to predict a value based on other features by constructing a linear relationship between the features and the predicted value. I've provided you guys with a training set and a testing set, we'll talk about how you can use this  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"PRICE\", \"Id\"])  # Drop target column\n",
    "y_train = train_df[\"PRICE\"]  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Model Evaluation\n",
    "For our purposes, we'll be evaluating on r-squared, the formula of which is provided below. This metric is essentially explaining the proportion of variance the relationship you are modeling accounts for. In simple terms, it is a measure of correlation of our linear model that is normalized between 0 and 1. Closer to 1 means generally more accurate and closer to 0 is less accurate (although if it is 1.0 exactly your model is probably overfitting).\n",
    "\n",
    "$$ \n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"R-squared: {r2_score(y_train, y_train_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the linear regression model only provides an r-squared of 0.61 so ts is some mid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of evaluating your model, you can use this helper method I have below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_file(model, test_features, name, submission_number):\n",
    "\n",
    "    ids = test_features[\"Id\"].astype(str) \n",
    "    test_features = test_features.drop(columns=[\"Id\"])  # drop 'Id' for prediction\n",
    "\n",
    "    X_test = test_features[X_train.columns]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"Id\": ids,  \n",
    "        \"Predicted\": y_pred \n",
    "    })\n",
    "\n",
    "    filename = f\"{name}_{submission_number}.csv\"\n",
    "    submission.to_csv(filename, index=False)\n",
    "\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_csv(\"test.csv\")\n",
    "generate_submission_file(model=model, test_features=test_features, name=\"Rahil\", submission_number=1) # update your submisssion number\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submissions & Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have your submission csv which should populate in your file directory after you run the above cell, see how your results compare with the rest of the PDM kaggle competition:\n",
    "\n",
    "1. Go to the below link:\n",
    "\n",
    "https://www.kaggle.com/competitions/pdm-linear-modeling-comp/code\n",
    "\n",
    "2. Click 'Submit Predictions'\n",
    "\n",
    "3. Then click 'Upload Submission'\n",
    "\n",
    "4. Click 'Submit'\n",
    "\n",
    "5. Check the 'Leaderboard' and see how your results compare!\n",
    "\n",
    "6. Submit as many submissions as you want, you should be able to achieve > 0.90 r2 on this dataset (try using random forest regression instead of linear regression, hyperparam tuning, feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Build a linear model and submit your csv on kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdmdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
